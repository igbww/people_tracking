# people_tracking
В ходе изучения  фреймфорка FairMOT  было выполнено:

**1. Разметка датасета для детекции совместно с остальными группами изучавшими встроенные трекеры YOLO и сторонние трекеры.**

**2. Конвертация лейблов формата YOLO** - 0 0.616093 0.552211 0.234644 0.414005 где 0 - class_id 0.616093 - center_x 0.552211 - center_y 0.234644 - width 0.414005 - height **в формат FairMOT** frame, id, bb_left, bb_top, bb_width, bb_height, conf, class, Visibility где: 

frame – порядковый номер фрейма.

id - Идентификатор рамки (-1), id детектируемого объекта (Каждая траиектория объекта идентифицируется уникальным идентификатором (-1 для обнаружения).

bb_left -  Координаты x (это center_x YOLO * размер изображения х).

bb_top -  Координаты y (это center_y YOLO * размер изображения у).

bb_width -  Ширина (это width YOLO * ширину зображения / 2).

bb_height -  Высота (это height YOLO * высоту зображения / 2).

conf -  Область уверенности (0-1) (1) другими словами точность детектируемого объекта.

class -  класс объекта как в YOLO class_id.

Visibility -  Видимость или коэфициент видимости от 0 до 1, который указывает, какая часть этого объекта видна. Может быть из-за окклюзии или обрезки границ изображения.

  После конвертации и ряда эксперементов на базовом репозитории https://github.com/NS19972/FairMOT было принято решение переразметки т.к. имеющийся датасет не показывал видимых результатов в отслеживании объектов.

**3. Было выполнено разбиение тренировочного видео с частотой до 30 кадров в секунду (частота обработки видео FairMOTом 26-30 кадров в сек), в ручную убраны пустые кадры и так же вручную поделены на тренировочную и валидационную выборки, идея заключалась в разметке трекингом (одного и того же идентификатора рамки) с помощью сервиса для разметки CVAT. Было размеченно порядка 9-10 тыс фреймов с общим количеством уникальных идентификаторов рамок = 297 (7 классов, Человек, Человек в каске, Человек в жилете, Человек в каске в жилете, Охранник, Каска, Жилет).**

**4. Формирование лейблов для обучения происходит с помощью файла gen_labels_mot16_cvat.py на основании gt.txt (выгруженный формат оннотаций MOT 1.1 с сервиса CVAT) и аннотаций в формате .xml (выгруженных с сервиса CVAT в формате CVAT for images 1.1)**

**5. Были выполнены эксперементы с различными архитектурами базового репозитория** https://github.com/NS19972/FairMOT (без новой разметки) и **второстепенного репозитория ** https://github.com/CaptainEven/MCMOT на новой разметке. **Есть в планах эксперементы с детектором YOLOv4 репозитория** https://github.com/CaptainEven/YOLOV4_MCMOT

**6. Были изменены базовые файлы для генерации лейблов для последующего обучения сети (gen_labels_mot16_cvat.py).**

**7. Для обучения был добавлен файл запуска обучения train_val.py с выводом валидационной ошибки (в исходном такой функции прописано не было)**

При запуске последнего блокнота обучения не забудьте поменять пути сохранения моделей на гугл диск в файле запуска обучения 
train_val.py

Большая часть и финальные (с трекинговой разметкой) эксперементы проводились на локальной машине. До обучение сети имеет эфективность в 10-20% по времени, что бы достич предыдущих результатов обучаемой модели. Поэтому вариант до обучения весьма затягивается.

**Графики обучения архитектур FairMOT с валидацией**

![График обучения dla34 на 30 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/dla34_30_epoch.png)

![График обучения resdcn18 на 120 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/resdcn18_120_epoch.png)

![График обучения resdcn34 на 54 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/resdcn34_54_epoch.png)

![График обучения cspdarknet53 на 19 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/cspdarknet53_19_epoch.png)

![График обучения resfpndcn34 на 96 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/resfpndcn34_96_epoch.png)

![График обучения yolo5s на 33 эпохах](https://github.com/terrainternship/people_tracking/blob/Group_5_MOT/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F/yolo5s_33_epoch.png)

**Так же стоит отметить две отправные точки обучения:**

1. При обучении без учета валидации, ошибка по всем параметрам постоянно снижается, спустя 50 эпох, понимажается шаг обучения что способствует увеличению понижения ошибки с каждой эпохой (параметр настраивается).

2. При обучении с валидацией, модель уходит в переобучение с 12-35 эпохи, при обучении разных архитектур.

**Выводы:** на данный момент проводится обучение различных архитектур с репозитория https://github.com/CaptainEven/MCMOT полноценно с train и val. После подбора лучшей архитектуры. В качестве эксперементов можно поменять датасет местами 20% train и 80 val для просмотра зависимости переобучения от размера дата сета (пока без его увеличения за счёт новой разметки). 